{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0728d3b5",
   "metadata": {},
   "source": [
    "# Model fit on one experimental trial #\n",
    "\n",
    "This notebook was originally designed to reproduce figure 4g of the paper: the BLS model comparison across all behavioral sessions, where the authors fitted both Bayesian timing models to each session and compared their goodness of fit using the Mean Squared Error (MSE) between empirical and model-predicted timing behavior. \n",
    "\n",
    "Because we only have access to one empirical trial per monkey (from the data accompanying Figure 1b), we cannot recreate the session-level comparison in Fig. 4g. Instead, we apply the same fitting procedures and compute analogous metrics on the single available trial for each animal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742d0df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from Identifiability_test import CounterModel, NonCounterModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043d202f",
   "metadata": {},
   "source": [
    "**Data description:** \n",
    "\n",
    "The Figure 1b data files provide two vectors:\n",
    "- $v_a(t)$ : actual velocity\n",
    "- $v_p(t)$ : predicted velocity \n",
    "\n",
    "Velocity is signed, but its magnitude corresponds to the timing interval. We extract vectors $t_s, t_p$ where $t_s$ is the true interval encoded in the trial and $t_p$ is the produced interval  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99043117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nhp_id</th>\n",
       "      <th>va_mnav</th>\n",
       "      <th>vp_mnav</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>nhp_id.1</th>\n",
       "      <th>va_mnav.1</th>\n",
       "      <th>vp_mnav.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-0.416667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-1.366666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.233334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-1.383333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.416644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nhp_id  va_mnav   vp_mnav  Unnamed: 3 nhp_id.1  va_mnav.1  vp_mnav.1\n",
       "0      a    -0.65 -0.416667         NaN        m       2.60   1.483333\n",
       "1      a    -0.65 -0.550000         NaN        m       0.65   0.783333\n",
       "2      a    -1.95 -1.366666         NaN        m       2.60   2.233334\n",
       "3      a    -1.95 -1.383333         NaN        m       1.95   2.416644\n",
       "4      a    -1.95 -0.550000         NaN        m       0.65   0.833333"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = pd.ExcelFile(r\"C:\\Users\\frdes\\Documents\\Neuroscience\\Project\\mental-navigation\\src\\mental_navigation\\Fig1\\Data_Fig1.xlsx\")\n",
    "df = pd.read_excel(file, sheet_name=\"fig_1b\")\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e59a8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   va_mnav   vp_mnav\n",
      "0    -0.65 -0.416667\n",
      "1    -0.65 -0.550000\n",
      "2    -1.95 -1.366666\n",
      "3    -1.95 -1.383333\n",
      "4    -1.95 -0.550000\n",
      "   va_mnav   vp_mnav\n",
      "0     2.60  1.483333\n",
      "1     0.65  0.783333\n",
      "2     2.60  2.233334\n",
      "3     1.95  2.416644\n",
      "4     0.65  0.833333\n",
      "Samples monkey A: 1028\n",
      "va_mnav    0\n",
      "vp_mnav    0\n",
      "dtype: int64\n",
      "Samples monkey M: 1382\n",
      "va_mnav    0\n",
      "vp_mnav    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_a= df[['va_mnav','vp_mnav']].copy()\n",
    "df_m = df[['va_mnav.1','vp_mnav.1']].copy()\n",
    "df_m = df_m.rename(columns= {'va_mnav.1':'va_mnav','vp_mnav.1':'vp_mnav'})\n",
    "print(df_a.head())\n",
    "print(df_m.head())\n",
    "df_a = df_a.dropna(subset=['va_mnav','vp_mnav'])\n",
    "print('Samples monkey A:',len(df_a))\n",
    "print(df_a.isna().sum())\n",
    "df_m = df_m.dropna(subset=['va_mnav','vp_mnav'])\n",
    "print('Samples monkey M:',len(df_m))\n",
    "print(df_m.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f867653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use absolute velocities as times \n",
    "ts_a = df_a[\"va_mnav\"].to_numpy()\n",
    "tp_a = df_a[\"vp_mnav\"].to_numpy()\n",
    "\n",
    "ts_m = df_m[\"va_mnav\"].to_numpy()\n",
    "tp_m = df_m[\"vp_mnav\"].to_numpy()\n",
    "\n",
    "# abs to match format required by my code (as in the Matlab one)\n",
    "ts_a = np.abs(ts_a)\n",
    "tp_a = np.abs(tp_a)\n",
    "ts_m = np.abs(ts_m)\n",
    "tp_m = np.abs(tp_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b50f00c",
   "metadata": {},
   "source": [
    "For both the **Counter model** (with reset) and the **Non-Counter model** (without reset) we estimate parameters  $$ \\theta = (w_m,w_p,offset) $$ on the actual data using maximum likelihood. We then computed standard goodnes-of-fit measures like:\n",
    "- Negative log-likelihood $ L $\n",
    "- BIC: $$ \\text{BIC} = kln(n) + 2(-log L)$$ \n",
    "- Single-trial MSE: the simple squared error between true values and one noisy model-generated sample (using the best fit parameters), to see how close the sample is to actual trial. It is a stochastic error measure, multiple runs will result in different MSE values\n",
    "$$ MSE_{trial}= (t_p^{empirical}- t_p^{model})^2$$\n",
    "\n",
    "The single trial MSE differs from the MSE in the paper that we computed and is explained later on.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03965c5",
   "metadata": {},
   "source": [
    "The first model we fit is the Counter model using data from monkey A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24820d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter= CounterModel()\n",
    "\n",
    "res_counter= counter.fit(ts_a,tp_a,w_init = (0.5,0.5,0.0))\n",
    "\n",
    "# Recover the fitted parameters computed in .fit\n",
    "w_opt = res_counter.x\n",
    "wm_opt, wp_opt, offset_opt = w_opt \n",
    "print('Fitted parameters (wm,wp,offset):', w_opt)\n",
    "\n",
    "# Negative log-likelihood at optimum\n",
    "negloglik_opt= counter.neg_log_likelihood(w_opt,ts_a,tp_a)\n",
    "print('Negative log-likelihood at optimum:',negloglik_opt)\n",
    "\n",
    "# BIC (as in the Matlab code)\n",
    "n= len(ts_a)\n",
    "k= len(w_opt)\n",
    "bic = np.log(n)*k + 2*negloglik_opt\n",
    "print('BIC:',bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16f2395",
   "metadata": {},
   "source": [
    "The following cell computes the $MSE_{trial}$. \n",
    "\n",
    "In the sample run for **Counter model** on data from monkey **A** this value amounts to $MSE_{trial} = 0.49116851529704697 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad36d162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (trial-wise) = 0.49116851529704697\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(0) \n",
    "\n",
    "# Generate model predictions\n",
    "tm_gen, te_gen, tp_gen = counter.simulate(ts_a, wm_opt, wp_opt, offset_opt, rng=rng)\n",
    "mse_trial = np.mean((tp_a - tp_gen)**2)\n",
    "\n",
    "print(\"MSE (trial-wise) =\", mse_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e19b0",
   "metadata": {},
   "source": [
    "In the paper, for each session, authors compute:\n",
    "- the **mean empirical produced time** $\\bar{t}_p(t_s)$ which is simply the mean of all produced intervals $ t_p $ that are relative to a specific time 'bin' $ts$ , $ts \\in (0.65, 1.30, 1.95, 2.6, 3.25)$ \n",
    "$$\n",
    "\\bar{t}_p(t_s) = \\frac{1}{n_s} \\sum_{i : t_{s,i} = t_s} t_{p,i}\n",
    "$$\n",
    "\n",
    "- the **mean model-predicted produced time** $\\hat{t}_p(t_{s})$, whose computation in explained below\n",
    "- The **MSE** over the 5 base intervals \n",
    "$$\n",
    "\\mathrm{MSE}_{\\text{session}}\n",
    "= \\frac{1}{5} \\sum_{j=1}^{5}\n",
    "\\left( \\bar{t}_p(t_{s,j}) - \\hat{t}_p(t_{s,j}) \\right)^2\n",
    "$$\n",
    "\n",
    "This is a deterministic model-data comparison of the mean curves, not of individual samples \n",
    "\n",
    "The mean model predicted produced interval  is obtained from the expected value of $t_p$ conditioned on a given base interval $t_s$:\n",
    "$$\n",
    "\\hat{t}_p(t_s) = \\mathbb{E}\\big[\\, t_p \\mid t_s, \\theta \\,\\big]\n",
    "$$\n",
    "\n",
    "Since the BLS generative model includes measurement noise and production noise, this is not available in closed form. \n",
    "Therefore, we approximate it using Monte Carlo sampling: \n",
    "1) For each unique value of $t_s$\n",
    "2) Simulate a large batch of trial ($n= 5000$) collecting the resulting $t_p$ values \n",
    "3) Take their mean, so the approximation would be: \n",
    "$$\n",
    "\\hat{t}_p(t_s) \\approx \\frac{1}{N} \\sum_{i=1}^{N} t_{p,i}^{\\text{model}}\n",
    "$$\n",
    "\n",
    "We then use this approximation in the **$MSE_{session}$** computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2285fc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tp_mean_per_ts_from_model(model, ts_empirical, wm, wp, offset,\n",
    "                                      n_samples=5000, rng=None):\n",
    "    \"\"\"\n",
    "    Approximate the model-predicted mean produced time for each unique ts\n",
    "    by Monte Carlo using model.simulate.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : BaseBayesianTimingModel (CounterModel or NonCounterModel)\n",
    "    ts_empirical : 1D array of empirical ts from the session\n",
    "    wm, wp, offset : fitted parameters for this model and this session\n",
    "    n_samples : number of simulated trials per unique ts\n",
    "    rng : numpy Generator (optional, for reproducibility)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    unique_ts : 1D array of sorted unique ts values\n",
    "    tp_model_mean : 1D array, same length as unique_ts\n",
    "    tp_model_mean[i] â‰ˆ E[tp | ts = unique_ts[i], theta]\n",
    "    \"\"\"\n",
    "    ts_empirical = np.asarray(ts_empirical, dtype=float)\n",
    "    print(ts_empirical)\n",
    "    unique_ts = np.unique(ts_empirical)\n",
    "\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng(123)\n",
    "\n",
    "    tp_model_mean = np.empty_like(unique_ts, dtype=float)\n",
    "\n",
    "    for i, t in enumerate(unique_ts):\n",
    "        # simulate n_samples trials all with the same ts = t\n",
    "        ts_vec = np.full(n_samples, t, dtype=float)\n",
    "        # Here it simulates the trials\n",
    "        _, _, tp_sim = model.simulate(ts_vec, wm, wp, offset, rng=rng)\n",
    "        print(\"ts =\", t,\n",
    "              \"| any NaN in tp_sim?\", np.isnan(tp_sim).any(),\n",
    "              \"| #NaN =\", np.isnan(tp_sim).sum())\n",
    "        if np.isnan(tp_sim).any():\n",
    "            print('Warning: some samples returned Nan and were discarded from the mean computation')\n",
    "\n",
    "        # Here it maps the interval to the mean \n",
    "        #tp_model_mean[i] = tp_sim.mean()\n",
    "        tp_model_mean[i] = np.nanmean(tp_sim)\n",
    "        \n",
    "    print(tp_model_mean)\n",
    "    return unique_ts, tp_model_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979956e2",
   "metadata": {},
   "source": [
    "The following cell contains an helper function to compute the MSE given the true behavioural $t_p$  and the model mean $t_p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6311d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_means_only(ts, tp_data, tp_model_mean):\n",
    "    \"\"\"\n",
    "    MSE between empirical mean tp(ts) and model-predicted mean tp(ts).\n",
    "    \"\"\"\n",
    "    ts = np.asarray(ts)\n",
    "    tp_data = np.asarray(tp_data)\n",
    "    tp_model_mean = np.asarray(tp_model_mean)  # one value per unique ts\n",
    "\n",
    "    unique_ts = np.unique(ts)\n",
    "    mse_vals = []\n",
    "\n",
    "    for i, t in enumerate(unique_ts):\n",
    "        mask = (ts == t)\n",
    "        data_mean = tp_data[mask].mean()\n",
    "        model_mean = tp_model_mean[i]  # model gives one predicted mean per ts\n",
    "        mse_vals.append((data_mean - model_mean)**2)\n",
    "\n",
    "    return np.mean(mse_vals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b2302",
   "metadata": {},
   "source": [
    "The following cells computes the **MSE** for the **Counter model**. This value comes out to be $$ MSE_{session} = 0.1252836794984097$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00bb2296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65 0.65 1.95 ... 0.65 0.65 2.6 ]\n",
      "ts = 0.65 | any NaN in tp_sim? True | #NaN = 32\n",
      "Warning: some samples returned Nan and were discarded from the mean computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frdes\\Documents\\Neuroscience\\Project\\mental-navigation\\src\\mental_navigation\\Bayesianmodels\\Identifyability.py:227: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return wp * np.sqrt(te)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts = 1.3 | any NaN in tp_sim? True | #NaN = 3\n",
      "Warning: some samples returned Nan and were discarded from the mean computation\n",
      "ts = 1.95 | any NaN in tp_sim? True | #NaN = 1\n",
      "Warning: some samples returned Nan and were discarded from the mean computation\n",
      "ts = 2.6 | any NaN in tp_sim? False | #NaN = 0\n",
      "ts = 3.25 | any NaN in tp_sim? False | #NaN = 0\n",
      "[0.45995857 1.10442554 1.75601506 2.40046377 3.04575833]\n",
      "MSE value of Counter model: 0.1252836794984097\n"
     ]
    }
   ],
   "source": [
    "# Previously fitted parameters are here: wm_opt, wp_opt, offset_opt = w_opt \n",
    "\n",
    "# generate model predicted mean \n",
    "unique_ts,tp_model_mean = predict_tp_mean_per_ts_from_model(\n",
    "                                        model= counter,\n",
    "                                        ts_empirical = ts_a, \n",
    "                                        wm = wm_opt,\n",
    "                                        wp = wp_opt,\n",
    "                                        offset = offset_opt,\n",
    "                                        n_samples = 5000,\n",
    "                                        rng= np.random.default_rng(0) \n",
    "                                    )\n",
    "\n",
    "mse_val= mse_means_only(ts_a,tp_a,tp_model_mean)\n",
    "print('MSE value of Counter model:', mse_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7353a5b4",
   "metadata": {},
   "source": [
    "In the following cells we reproduce the same computations using data from monkey **A** on **Non Counter model** . The trial $MSE$ for the Non Counter model is: \n",
    "$$ MSE_{trial} = 0.5152966061705184 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcdf5e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted parameters (wm,wp,offset): [ 0.220947    0.23183494 -0.17881231]\n",
      "Negative log-likelihood at optimum: 669.4253037232046\n",
      "BIC: 1359.6567187844546\n"
     ]
    }
   ],
   "source": [
    "noncounter= NonCounterModel()\n",
    "\n",
    "res_counter_n= noncounter.fit(ts_a,tp_a,w_init = (0.5,0.5,0.0))\n",
    "# Recover the fitted parameters computed in .fit\n",
    "w_opt_n = res_counter_n.x\n",
    "wm_opt_n, wp_opt_n, offset_opt_n = w_opt_n \n",
    "print('Fitted parameters (wm,wp,offset):', w_opt_n)\n",
    "\n",
    "# Negative log-likelihood at optimum\n",
    "negloglik_opt_n= noncounter.neg_log_likelihood(w_opt_n,ts_a,tp_a)\n",
    "print('Negative log-likelihood at optimum:',negloglik_opt_n)\n",
    "\n",
    "# BIC (as in the Matlab code)\n",
    "n_n= len(ts_a)\n",
    "k_n= len(w_opt_n)\n",
    "bic_n = np.log(n_n)*k_n + 2*negloglik_opt_n\n",
    "print('BIC:',bic_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fee8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (trial-wise) = 0.5152966061705184\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "# Generate model predictions\n",
    "tm_gen_n, te_gen_n, tp_gen_n = noncounter.simulate(ts_a, wm_opt_n, wp_opt_n, offset_opt_n, rng=rng)\n",
    "mse_trial_n = np.mean((tp_a - tp_gen_n)**2)\n",
    "print(\"MSE (trial-wise) =\", mse_trial_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda815c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65 0.65 1.95 ... 0.65 0.65 2.6 ]\n",
      "ts = 0.65 | any NaN in tp_sim? False | #NaN = 0\n",
      "ts = 1.3 | any NaN in tp_sim? False | #NaN = 0\n",
      "ts = 1.95 | any NaN in tp_sim? False | #NaN = 0\n",
      "ts = 2.6 | any NaN in tp_sim? False | #NaN = 0\n",
      "ts = 3.25 | any NaN in tp_sim? False | #NaN = 0\n",
      "[0.47358655 1.12216718 1.77622295 2.41903607 3.06434245]\n",
      "MSE value of NonCounter model: 0.12789651924728931\n"
     ]
    }
   ],
   "source": [
    "# Previously fitted parameters are here: wm_opt_n, wp_opt_n, offset_opt_n = w_opt_n \n",
    "# generate model predicted mean \n",
    "unique_ts_n,tp_model_mean_n = predict_tp_mean_per_ts_from_model(\n",
    "                                        model= noncounter,\n",
    "                                        ts_empirical = ts_a, \n",
    "                                        wm = wm_opt_n,\n",
    "                                        wp = wp_opt_n,\n",
    "                                        offset = offset_opt_n,\n",
    "                                        n_samples = 5000,\n",
    "                                        rng= np.random.default_rng(0) \n",
    "                                    )\n",
    "\n",
    "mse_val_n= mse_means_only(ts_a,tp_a,tp_model_mean_n)\n",
    "print('MSE value of NonCounter model:', mse_val_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a3fd94",
   "metadata": {},
   "source": [
    "Here's the summary of the $MSE_{session}$ values obtained for the two models:\n",
    "- Counter model: \n",
    "$$\n",
    "MSE_{session}:  0.1252836794984097\n",
    "$$\n",
    "- Non Counter model: \n",
    "$$\n",
    "MSE_{session}:  0.12789651924728931\n",
    "$$\n",
    "\n",
    "As these values are only for one session, we cannot reproduce any of the further statistical analyses and visualisations conducted in the paper."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projneuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
